#Article Discussion

[Racist Software](https://www.theguardian.com/technology/2017/dec/04/racist-facial-recognition-white-coders-black-people-police)

Many people often describe code as something that is inherently objective -- free from any sort of bias. They therefore come to the conclusion that the types of people who create the code is irrelevant. However, this article demonstrates how even *software*, which seems so detached from humanity, can be **racist**.

A facial recognition software that has begun to be widely employed among law enforcement agencies, was not only shown to be highly inaccurate in correctly identifying suspects, but more likely to produce an incorrect result when the subject was *black*(Corroborated by the FBI's own research). This combined with the fact that facial recognition software is more likely to be leveraged when a subject is black creates a disastrous situation. Research suggests that the issues with the software are a result of it being created by 
solely white/non-black engineers. Certain facial features may be more visible in one race than another.
